{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from requests import post\n",
    "from requests.exceptions import ConnectionError\n",
    "from time import sleep\n",
    "from os import environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama server started on port 4200\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "\n",
    "def find_available_port(start_port=4200, end_port=4300):\n",
    "        for port in range(start_port, end_port + 1):\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "                try:\n",
    "                    s.bind(('127.0.0.1', port))\n",
    "                    return port\n",
    "                except socket.error:\n",
    "                    continue\n",
    "        raise ValueError(f\"No available ports found in the range {start_port}-{end_port}\")\n",
    "\n",
    "port = find_available_port()\n",
    "\n",
    "def start_server(port):\n",
    "        command = f\"OLLAMA_HOST=localhost:{port} ollama serve\"\n",
    "        try:\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "            print(f\"Ollama server started on port {port}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error starting Ollama server on port {port}: {e}\")\n",
    "        \n",
    "        return process\n",
    "\n",
    "process = start_server(port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "def generate_response(prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Generates an http request to the ollama server and returns the response.\n",
    "\n",
    "        :param prompt: The prompt to send to the model.\n",
    "        :return: The response from the model.\n",
    "        \"\"\"\n",
    "        data = {\n",
    "            \"model\": 'dolphin2.2-mistral',\n",
    "            \"stream\": False,\n",
    "            \"prompt\": prompt,\n",
    "        }\n",
    "\n",
    "        completion_headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "        }\n",
    "\n",
    "        url = f\"http://localhost:11434/api/generate\"\n",
    "        try:\n",
    "            response = requests.post(url, headers=completion_headers, data=prompt)\n",
    "            print(f\"Response: {response}\")\n",
    "            if response.status_code == 200:\n",
    "                response_text = response.text\n",
    "                data = json.loads(response_text)\n",
    "                response_content = data[\"response\"]\n",
    "\n",
    "                return response_content\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: <Response [400]>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "response_text = generate_response(prompt='hello, how are you?')\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1441850263.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[40], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    curl http://localhost:1313/api/generate -d '{\"model\": \"llama2\",\"prompt\": \"Why is the sky blue?\",\"stream\": false}'\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import curl\n",
    "\n",
    "curl http://localhost:1313/api/generate -d '{\"model\": \"llama2\",\"prompt\": \"Why is the sky blue?\",\"stream\": false}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":\"model 'llama2-uncensored' not found, try pulling it first\"}\n"
     ]
    }
   ],
   "source": [
    "request = requests.post('http://localhost:1313/api/generate', data='{\"model\": \"llama2-uncensored\",\"prompt\": \"Why is the sky blue?\",\"stream\": false}')\n",
    "print(request.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
